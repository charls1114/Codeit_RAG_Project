# 공통
RAG_MODE=local_hf              # 또는 openai_api
DOC_LOADER_BACKEND=pymupdf_teddynote  # 또는 llamaindex_file

# LangSmith
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=
LANGCHAIN_PROJECT=rfp-rag-project

# 시나리오 1: 로컬 HF
HF_HOME=/path/to/hf_cache
HF_MODEL_NAME=meta-llama/Llama-3-8b-instruct
HF_EMBEDDING_MODEL=sentence-transformers/all-mpnet-base-v2
DEVICE=cuda                    # cpu / cuda

# 시나리오 2: OpenAI API
OPENAI_API_KEY=
OPENAI_MODEL_NAME=gpt-5-mini
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# Chroma
CHROMA_PERSIST_DIR=./data/chroma_db